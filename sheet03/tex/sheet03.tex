% exercise sheet with header on every page for math or close subjects
\documentclass[12pt]{article}
\usepackage[utf8]{inputenc} 
\usepackage{latexsym} 
\usepackage{multicol}
\usepackage{fancyhdr}
\usepackage{amsfonts} 
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumerate}
\usepackage{listings}
\usepackage{graphicx}

% Shortcuts for bb, frak and cal letters
\newcommand{\E}{\mathbb{E}}
\newcommand{\V}{\mathbb{V}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Pfrak}{\mathfrak{P}}
\newcommand{\Pfrac}{\mathfrak{P}}
\newcommand{\Bfrac}{\mathfrak{P}}
\newcommand{\Bfrak}{\mathfrak{B}}
\newcommand{\Fcal}{\mathcal{F}}
\newcommand{\Ycal}{\mathcal{Y}}
\newcommand{\Bcal}{\mathcal{B}}
\newcommand{\Acal}{\mathcal{A}}


% Formatierung
\topmargin -2cm 
\textheight 24cm
\textwidth 16.0 cm 
\oddsidemargin -0.1cm

\setlength{\parindent}{0pt}  % !!!!!!! Hier werden leerzeilen erlaubt ohne dass Latex automatisch einrueckt! !!!!!!! %


\graphicspath{ {images/} }


\begin{document}

% Titel
%\title{\textsc{Hacking}\\ \textsc{Abgabe 0}\\{ \normalsize Gruppe X \hfill Daniel Sch√§fer (2549458)\\ \hfill Anderer}}
%\maketitle  

% alternativer Titel
\noindent
{\Large \textbf{High-level Computer Vision}} \hfill \textbf{26.05.2016}\\
{\Large \textbf{Exercise 3}} 
\raggedleft \hfill Guillermo Reyes (2556018)\\
\hfill Daniel Schaefer (2549458)\\
\hfill Marc Tonsen (2537359)\\
\hfill Dominik Weber (2548553)\\

\pagenumbering{gobble}
\raggedright


\section*{Code Annotations}




\section*{Question 1: Support Vector Machines}

\begin{enumerate}[a)]
	\setcounter{enumi}{1}
	\item 	
        \textbf{Modify the last two parameters of} \verb!get\_train\_dataset\_2d.m! \textbf{in order to make the classification problem linearly non-separable. Run your visualization for different values of parameter C and comment on its role in the SVM classification algorithm.}\\
        
        	\begin{figure}[h]			
        		\includegraphics[width=0.5\textwidth]{1b_separable}
        		\includegraphics[width=0.5\textwidth]{1b_non-separable}
        		\caption{\textit{Left}: SVM for linearly separable data with default parameters. $ \sigma_1=1.5, \sigma_2=5 $. \textit{Right}: SVM for linearly non-separable data. The same parameters are used to generate the data except that $ \sigma_1=10 $ and $\sigma_2=10 $ }
        	\end{figure}
        
		The parameter C is used in the minimized loss function to tune the importance of the sum of $\xi$'s. A high value for C would put a lot of importance on them and would therefore force them to take very small values. Therefore, the higher the value of C is, the closer the performance comes to that of a hard-margin SVM. If C has a small value this would soften the margin and would also allow support vectors that are further further away from the margin. In conclusion C influences how soft the margin of the SVM is.
\end{enumerate}

\newpage
\section*{Question 3: Performance Evaluation}
\begin{enumerate}[a)]
	\setcounter{enumi}{3}
	

	\item
        \textbf{Write a summary of your observations and submit it along with the corresponding RPC curves}\\
        %TODO

	\item 
        \textbf{How could you use the system to solve the detection problem in which you are given an image of arbitrary size and the task is to find the position of the people in it?}\\
        We could train the system a few times to work on images of different scale (i.e. train a separate system per scale). Then we could run those systems on the input image of arbitrary size in a sliding window fashion: For each scale pick uniformly spread patches of that size from the image and run the classifier on them. If the content of a patch is classified as an object of interest, we can return the bounding box of that patch as a detection result for that kind of object. One should be careful not to report the same object multiple times because it was recognized in multiple patches. Comparing the spacial relation of the bounding boxes can help to find the tightest bounding box out of all candidates. \\
        This way we can recognize and localize objects in the input image with only our classification system. However the accuracy of the localization is limited by the smallest scale for which we have a classifier (i.e. the smallest possible bounding box corresponds to the size of the smallest scale) and objects in the image that are bigger then the size of the largest scale might not be found.\\
        Assuming we don't care about the time our programm takes to detect the human, we have the possibility to iterate from really tiny patch sizes to very big patch sizes, and move the patches only 1 pixel for every iteration of this patch-size. This way we can return the smallest possible patch we found, which contained a human according to our algorithm without having to iteratate over all possible patch-sizes and all possible patch placements. It's obvious that this naive approach still has extremely terrible running time. It's all about finding a balance here depending on how precise you want the detection to be.

\end{enumerate}


\end{document}
